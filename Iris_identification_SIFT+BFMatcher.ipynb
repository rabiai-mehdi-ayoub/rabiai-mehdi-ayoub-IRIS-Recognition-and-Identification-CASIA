{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3b146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import inspect\n",
    "from matplotlib import pyplot as plot\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339fd93",
   "metadata": {},
   "source": [
    "### une fonction pour Traite une image pour identifier et extraire la région de l'iris, détecte les points clés et calcule les descripteurs en utilisant d'autres fonctions auxiliaires.(fonction dapple )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2844c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_regions(image_path):\n",
    "    image = read_image(image_path, display=False)\n",
    "\n",
    "    print(\"Identifying iris boundaries...\")\n",
    "    inner_circle, outer_circle = locate_iris_boundaries(image, display=False)\n",
    "    if not inner_circle or not outer_circle:\n",
    "        print(\"Error locating iris boundaries!\")\n",
    "        return\n",
    "\n",
    "    print(\"Equalizing histogram...\")\n",
    "    region = equalize_iris_region(image, outer_circle, inner_circle, display=False)\n",
    "\n",
    "    print(\"Extracting iris region images...\")\n",
    "    regions = segment_regions(region, inner_circle, outer_circle, display=False)\n",
    "\n",
    "    print(\"Detecting keypoints...\")\n",
    "    sift_engine = sift = cv2.SIFT_create()\n",
    "    detect_keypoints(sift_engine, regions, display=False)\n",
    "    compute_descriptors(sift_engine, regions)  \n",
    "\n",
    "    return regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff745cf1",
   "metadata": {},
   "source": [
    "Lit une image depuis un chemin donné et affiche l'image si demandé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66151462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, display=False):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    if display:\n",
    "        cv2.imshow(image_path, image)\n",
    "        char = cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e56279",
   "metadata": {},
   "source": [
    "### Fonction : locate_iris_boundaries\n",
    "Détecte dynamiquement les limites internes et externes de l'iris en ajustant progressivement les paramètres de recherche en fonction des résultats initiaux.\n",
    "(La détection est effectuée dans d'autres fonctions. Cette fonction utilise les autres fonctions afin de détecter les bordures et ajuste les paramètres jusqu'à ce que les limites soient trouvées.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1990c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_iris_boundaries(image, display=False):\n",
    "    inner_circle = detect_inner_circle(image)\n",
    "\n",
    "    if not inner_circle:\n",
    "        print('ERROR: Inner circle not found!')\n",
    "        return None, None\n",
    "\n",
    "    radius_expansion = int(math.ceil(inner_circle[2]*1.5))\n",
    "    expansion_factor = 0.25\n",
    "    range_center = int(math.ceil(inner_circle[2]*expansion_factor)) \n",
    "    outer_circle = detect_outer_circle(\n",
    "                        image, inner_circle, range_center, radius_expansion)\n",
    "\n",
    "    while(not outer_circle and expansion_factor <= 0.7):\n",
    "        expansion_factor += 0.05\n",
    "        print('Searching outer iris circle with expansion factor ' + str(expansion_factor))\n",
    "\n",
    "        range_center = int(math.ceil(inner_circle[2]*expansion_factor))\n",
    "        outer_circle = detect_outer_circle(image, inner_circle,\n",
    "                                        range_center, radius_expansion)\n",
    "    if not outer_circle:\n",
    "        print('ERROR: Outer iris circle not found!')\n",
    "        return None, None\n",
    "    \n",
    "    if display:\n",
    "        color_image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "        draw_detected_circles(color_image, inner_circle, outer_circle,\n",
    "                     range_center, radius_expansion)\n",
    "        cv2.imshow('iris boundaries', color_image)\n",
    "        char = cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return inner_circle, outer_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21878b38",
   "metadata": {},
   "source": [
    "### Fonction : detect_inner_circle\n",
    "Détecte le cercle intérieur de l'iris en appliquant des filtres et en ajustant les seuils de manière dynamique pour optimiser la détection des cercles via la transformation de Hough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a41ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_inner_circle(image):\n",
    "    def extract_edges(processed_image):\n",
    "        edges = cv2.Canny(processed_image, 20, 100)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "        blur_size = 2 * random.randrange(5, 11) + 1\n",
    "        edges = cv2.GaussianBlur(edges, (blur_size, blur_size), 0)\n",
    "        return edges\n",
    "\n",
    "    circle_param1 = 200  # High threshold for Canny\n",
    "    circle_param2 = 120  # Accumulator threshold for circle detection\n",
    "    candidate_circles = []\n",
    "    while(circle_param2 > 35 and len(candidate_circles) < 100):\n",
    "        for median_filter_size, threshold in [(m, t) for m in [3, 5, 7] for t in [20, 25, 30, 35, 40, 45, 50, 55, 60]]:\n",
    "            # Apply median blur\n",
    "            blurred = cv2.medianBlur(image, 2 * median_filter_size + 1)\n",
    "\n",
    "            # Apply threshold\n",
    "            _, binary_image = cv2.threshold(blurred, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            # Fill contours\n",
    "            contours, _ = cv2.findContours(binary_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            filled_contours = cv2.drawContours(binary_image, contours, -1, (255), -1)\n",
    "\n",
    "            # Extract edges\n",
    "            edges = extract_edges(binary_image)\n",
    "\n",
    "            # Detect circles using Hough transform\n",
    "            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 1, np.array([]), circle_param1, circle_param2)\n",
    "            if circles is not None and circles.size > 0:\n",
    "                # Convert the circle parameters to integers\n",
    "                circles = np.round(circles[0, :]).astype(\"int\")\n",
    "                for circle in circles:\n",
    "                    candidate_circles.append(circle)\n",
    "\n",
    "        circle_param2 = circle_param2 - 1\n",
    "\n",
    "    if len(candidate_circles) == 0:\n",
    "        print(\"No inner circles detected.\")\n",
    "        return None\n",
    "\n",
    "    return calculate_average_circle(candidate_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156620",
   "metadata": {},
   "source": [
    "### Fonction : calculate_average_circle\n",
    "Calcule et retourne les coordonnées moyennes et le rayon moyen à partir d'une liste de cercles détectés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943dcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_average_circle(circles):\n",
    "    if not circles:\n",
    "        return\n",
    "    average_x = int(np.mean([c[0] for c in circles]))\n",
    "    average_y = int(np.mean([c[1] for c in circles]))\n",
    "    average_radius = int(np.mean([c[2] for c in circles]))\n",
    "\n",
    "    return average_x, average_y, average_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2018e",
   "metadata": {},
   "source": [
    "### Fonction : identify_optimal_radius\n",
    "Identifie le rayon optimal en minimisant la distance totale par rapport aux autres rayons dans la liste, permettant une sélection plus précise du cercle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a99e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_optimal_radius(circle_list):\n",
    "    optimal_circle = None\n",
    "    minimum_distance = None\n",
    "    reference_circles = circle_list[:]\n",
    "    comparison_circles = circle_list[:]\n",
    "    for current_circle in reference_circles:\n",
    "        total_distance = 0\n",
    "        for compared_circle in comparison_circles:\n",
    "            total_distance += math.fabs(float(current_circle[2]) - float(compared_circle[2]))\n",
    "        if not minimum_distance or total_distance < minimum_distance:\n",
    "            minimum_distance = total_distance\n",
    "            optimal_circle = current_circle\n",
    "    return optimal_circle[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63d45e",
   "metadata": {},
   "source": [
    "### Fonction : detect_outer_circle\n",
    "Détecte dynamiquement le cercle extérieur de l'iris en analysant les bords de l'image traitée. La fonction utilise plusieurs tailles de flou médian et des seuils de détection ajustés itérativement pour identifier les cercles par transformation de Hough. La détection continue jusqu'à ce que le nombre cible de cercles soit atteint ou que les seuils de détection soient épuisés, tout en vérifiant que les cercles détectés se trouvent bien à l'extérieur du cercle intérieur mais dans les limites spécifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60996ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_outer_circle(image, inner_circle, center_range, radius_range):\n",
    "    def extract_edges(processed_image, upper_threshold):\n",
    "        lower_threshold = 0  # Fixed low threshold for Canny\n",
    "        edges = cv2.Canny(processed_image, lower_threshold, upper_threshold, apertureSize=5)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "        blur_size = 2 * random.randrange(5,11) + 1\n",
    "        edges = cv2.GaussianBlur(edges,(blur_size,blur_size),0)\n",
    "        return edges\n",
    "\n",
    "    def find_circles(hough_threshold, median_sizes, edge_thresholds):\n",
    "        detected_circles = []\n",
    "        for median_size, upper_threshold in [(m, t) for m in median_sizes for t in edge_thresholds]:\n",
    "            # Apply median blur\n",
    "            median_blurred = cv2.medianBlur(image, 2 * median_size + 1)\n",
    "\n",
    "            # Extract edges\n",
    "            edges = extract_edges(median_blurred, upper_threshold)\n",
    "\n",
    "            # Detect circles using Hough transform\n",
    "            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                                       param1=200, param2=hough_threshold, minRadius=0, maxRadius=0)\n",
    "            if circles is not None and circles.size > 0:\n",
    "                # Convert the circle parameters to integers\n",
    "                circles = np.round(circles[0, :]).astype(\"int\")\n",
    "                for (col, row, radius) in circles:\n",
    "                    if within_circle(inner_circle[0], inner_circle[1], center_range, col, row) and radius > radius_range:\n",
    "                        detected_circles.append((col, row, radius))\n",
    "        return detected_circles\n",
    "\n",
    "    circle_param2 = 120  # Starting threshold for HoughCircles\n",
    "    all_circles = []\n",
    "    while(circle_param2 > 40 and len(all_circles) < 50):\n",
    "        circles = find_circles(\n",
    "                        circle_param2, [8,10,12,14,16,18,20], [430,480,530])\n",
    "        if circles:\n",
    "            all_circles += circles\n",
    "        circle_param2 = circle_param2 -1\n",
    "\n",
    "    if not all_circles:\n",
    "        print(\"Alternative strategy for detecting outer iris circle\")\n",
    "        circle_param2 = 120\n",
    "        while(circle_param2 > 40 and len(all_circles) < 50):\n",
    "            circles = find_circles(\n",
    "                            circle_param2, [3,5,7,21,23,25], [430,480,530])\n",
    "            if circles:\n",
    "                all_circles += circles\n",
    "            circle_param2 = circle_param2 -1\n",
    "\n",
    "    if not all_circles:\n",
    "        return\n",
    "\n",
    "    color_image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "    refined_circles = refine_circle_selection(all_circles)\n",
    "\n",
    "    return calculate_average_circle(refined_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608576b",
   "metadata": {},
   "source": [
    "### Fonction : within_circle\n",
    "Vérifie si un point donné se trouve à l'intérieur du rayon d'un cercle spécifié, en utilisant la distance entre le centre du cercle et le point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def within_circle(circle_col, circle_row, circle_radius, point_col, point_row):\n",
    "    return compute_distance(circle_col, circle_row, point_col, point_row) <= circle_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5992e",
   "metadata": {},
   "source": [
    "### Fonction : refine_circle_selection\n",
    "Affine la sélection de cercles détectés en filtrant ceux qui s'écartent significativement des moyennes calculées pour les positions et rayons. cet fonction Utilise des écarts types pour définir les seuils d'acceptation, en éliminant les cercles qui ne correspondent pas aux critères statistiques de cohérence des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_circle_selection(circles):\n",
    "    if not circles:\n",
    "        print('Error: No circles found in refine_circle_selection() !')\n",
    "        return []\n",
    "    center_x_mean, center_x_dev = compute_standard_deviation([int(i[0]) for i in circles])\n",
    "    center_y_mean, center_y_dev = compute_standard_deviation([int(i[1]) for i in circles])\n",
    "    refined = []\n",
    "    positions = []\n",
    "    unrefined = []\n",
    "    deviation_multiplier = 1.5 \n",
    "    for circle in circles[:]:\n",
    "        if circle[0] < center_x_mean - deviation_multiplier*center_x_dev or \\\n",
    "           circle[0] > center_x_mean + deviation_multiplier*center_x_dev or \\\n",
    "           circle[1] < center_y_mean - deviation_multiplier*center_y_dev or \\\n",
    "           circle[1] > center_y_mean + deviation_multiplier*center_y_dev:\n",
    "            unrefined.append(circle)\n",
    "        else:\n",
    "            positions.append(circle)\n",
    "    if len([float(c[2]) for c in positions]) < 3:\n",
    "        refined = positions\n",
    "    else:\n",
    "        optimal_radius = identify_optimal_radius(positions)\n",
    "        mean_radius, radius_deviation = compute_standard_deviation(\n",
    "                                    [float(c[2]) for c in positions])\n",
    "        max_radius = optimal_radius + radius_deviation\n",
    "        min_radius = optimal_radius - radius_deviation\n",
    "        for circle in positions:\n",
    "            if circle[2] < min_radius or \\\n",
    "               circle[2] > max_radius:\n",
    "                unrefined.append(circle)\n",
    "            else:\n",
    "                refined.append(circle)\n",
    "\n",
    "    return refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d5bce",
   "metadata": {},
   "source": [
    "### Fonction : draw_detected_circles\n",
    "Dessine les cercles détectés sur une image colorée, y compris les cercles internes et externes de l'iris, ainsi que les limites spécifiques de portée et de rayon si elles sont fournies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_detected_circles(colored_image, inner_circle, outer_circle,\n",
    "                 center_range=None, radius_range=None):\n",
    "    # draw the inner circle\n",
    "    cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), inner_circle[2],\n",
    "                     (0,0,255),1)\n",
    "    # draw the center of the inner circle\n",
    "    cv2.circle(colored_image,(inner_circle[0],inner_circle[1]),1,(0,0,255),1)\n",
    "    if center_range:\n",
    "        # draw outer circle center range limit\n",
    "        cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), center_range,\n",
    "                         (0,255,255),1)\n",
    "    if radius_range:\n",
    "        # draw outer circle radius range limit\n",
    "        cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), radius_range,\n",
    "                         (0,255,255),1)\n",
    "    # draw the outer circle\n",
    "    cv2.circle(colored_image, (outer_circle[0], outer_circle[1]), \n",
    "               outer_circle[2],(0,255,0),1)\n",
    "    # draw the center of the outer circle\n",
    "    cv2.circle(colored_image, (outer_circle[0], outer_circle[1]), \n",
    "               1,(0,255,0),1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe5511",
   "metadata": {},
   "source": [
    "### Fonction : equalize_iris_region\n",
    "Égalise l'histogramme d'une région spécifiée de l'iris, qui est délimitée par les cercles intérieur et extérieur, en masquant et en ajustant dynamiquement les niveaux d'intensité pour améliorer la visibilité et le contraste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def equalize_iris_region(image, outer_circle, inner_circle, display=False):\n",
    "    def locate_roi():\n",
    "        mask = image.copy()\n",
    "        mask[:] = (0)\n",
    "\n",
    "        cv2.circle(mask, \n",
    "                   (outer_circle[0], outer_circle[1]), \n",
    "                   outer_circle[2], (255), -1)\n",
    "        cv2.circle(mask,\n",
    "                   (inner_circle[0],inner_circle[1]),\n",
    "                   inner_circle[2],(0), -1)\n",
    "\n",
    "        region_of_interest = cv2.bitwise_and(image, mask)\n",
    "\n",
    "        return region_of_interest\n",
    "\n",
    "    region_of_interest = locate_roi()\n",
    "\n",
    "    # Mask the top part of the iris\n",
    "    for column_index in range(region_of_interest.shape[1]):\n",
    "        for row_index in range(region_of_interest.shape[0]):\n",
    "            angle = calculate_angle(outer_circle[0], outer_circle[1], \n",
    "                            column_index, row_index)\n",
    "            if angle > 50 and angle < 130:\n",
    "                region_of_interest[row_index,column_index] = 0\n",
    "\n",
    "    _, region_of_interest = cv2.threshold(region_of_interest,50,255,cv2.THRESH_TOZERO)\n",
    "\n",
    "    equalized_region = region_of_interest.copy()\n",
    "    cv2.equalizeHist(region_of_interest, equalized_region)\n",
    "    region_of_interest = cv2.addWeighted(region_of_interest, 0.0, equalized_region, 1.0, 0)\n",
    "\n",
    "    if display:\n",
    "        cv2.imshow('equalized histogram iris region', region_of_interest)\n",
    "        char = cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return region_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e9f65",
   "metadata": {},
   "source": [
    "### Fonction : segment_regions\n",
    "Segmente et isole la région de l'iris entre les cercles intérieur et extérieur pour un traitement ultérieur. Cette fonction ajuste également la position de la région segmentée pour centraliser les cercles de l'iris, appliquant une transformation pour aligner les images selon les nouveaux centres calculés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4de705",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def segment_regions(image, inner_circle, outer_circle, display=False):\n",
    "    background = image.copy()\n",
    "    background[:] = 0\n",
    "\n",
    "    regions = {'entire': {'image': background.copy(),\n",
    "                          'inner_circle': inner_circle,\n",
    "                          'outer_circle': outer_circle,\n",
    "                          'keypoints': None,\n",
    "                          'image_with_keypoints': background.copy(),\n",
    "                          'image_with_filtered_keypoints': background.copy(),\n",
    "                          'descriptors': None\n",
    "                         }}\n",
    "\n",
    "    for column_index in range(image.shape[1]):\n",
    "        for row_index in range(image.shape[0]):\n",
    "            if not within_circle(inner_circle[0], inner_circle[1], inner_circle[2], column_index, row_index) and \\\n",
    "               within_circle(outer_circle[0], outer_circle[1], outer_circle[2], column_index, row_index):\n",
    "                regions['entire']['image'][row_index,column_index] = image[row_index,column_index]\n",
    "\n",
    "    regions['entire']['outer_circle'] = (int(1.25*outer_circle[2]), \n",
    "                                         int(1.25*outer_circle[2]),\n",
    "                                         int(outer_circle[2]))\n",
    "    translate_x = regions['entire']['outer_circle'][0] - outer_circle[0]\n",
    "    translate_y = regions['entire']['outer_circle'][1] - outer_circle[1]\n",
    "    regions['entire']['inner_circle'] = (int(translate_x + inner_circle[0]),\n",
    "                                         int(translate_y + inner_circle[1]),\n",
    "                                         int(inner_circle[2]))\n",
    "\n",
    "    translation_matrix = np.float32([[1,0,translate_x],[0,1,translate_y]])\n",
    "    regions['entire']['image'] = cv2.warpAffine(\n",
    "                        regions['entire']['image'], translation_matrix, \n",
    "                        (image.shape[1], image.shape[0]))\n",
    "\n",
    "    regions['entire']['image'] = regions['entire']['image'][0:int(2.5 * outer_circle[2]), 0:int(2.5 * outer_circle[2])]\n",
    "\n",
    "    if display:\n",
    "        plot.imshow(regions['entire']['image'], cmap='gray')\n",
    "        plot.title('Entire'), plot.xticks([]), plot.yticks([])\n",
    "        plot.show()\n",
    "\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e409b7",
   "metadata": {},
   "source": [
    "### Fonction : detect_keypoints\n",
    "Détecte les points clés de la région de l'iris en utilisant l'algorithme SIFT, en excluant les points en dehors de la région spécifiée entre les cercles intérieur et extérieur. Les points clés valides sont visualisés sur l'image si demandé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_keypoints(sift_engine, regions, display=False):    \n",
    "    all_keypoints = sift_engine.detect(regions['entire']['image'], None)\n",
    "    valid_keypoints = []\n",
    "    for keypoint in all_keypoints:\n",
    "        x, y = keypoint.pt\n",
    "        if within_circle(regions['entire']['outer_circle'][0], regions['entire']['outer_circle'][1], regions['entire']['outer_circle'][2], x, y) and \\\n",
    "           not within_circle(regions['entire']['inner_circle'][0], regions['entire']['inner_circle'][1], regions['entire']['inner_circle'][2], x, y):\n",
    "            valid_keypoints.append(keypoint)\n",
    "    regions['entire']['keypoints'] = valid_keypoints\n",
    "\n",
    "    regions['entire']['image_with_keypoints'] = cv2.drawKeypoints(\n",
    "                                    regions['entire']['image'], regions['entire']['keypoints'],\n",
    "                                    color=(0,255,0), flags=0,\n",
    "                                    outImage=None)\n",
    "    if display:\n",
    "        plot.imshow(cv2.cvtColor(regions['entire']['image_with_keypoints'], cv2.COLOR_BGR2RGB))\n",
    "        plot.title('Entire Region with KeyPoints')\n",
    "        plot.axis('off')\n",
    "        plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab27273",
   "metadata": {},
   "source": [
    "### Fonction : compute_descriptors\n",
    "Calcule les descripteurs pour les points clés détectés dans la région de l'iris en utilisant l'engine SIFT. Affiche les dimensions des descripteurs si disponibles, signalant également quand aucun descripteur n'est trouvé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98acfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_descriptors(sift_engine, regions):\n",
    "    regions['entire']['keypoints'], regions['entire']['descriptors'] = sift_engine.compute(regions['entire']['image'], regions['entire']['keypoints'])\n",
    "    if regions['entire']['descriptors'] is not None:\n",
    "        print(f\"Entire Region, Descriptor Dimensions: {regions['entire']['descriptors'].shape}\")\n",
    "    else:\n",
    "        print(\"Entire Region, No descriptors found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d1210",
   "metadata": {},
   "source": [
    "### Fonction : match_all_regions\n",
    "Orchestre la comparaison des régions entre deux images en utilisant la fonction `find_matches` pour obtenir les correspondances. Visualise ces correspondances et indique leur nombre total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_all_regions(regions_one, regions_two, ratio_threshold, angle_standard_deviation, distance_standard_deviation, display=False):\n",
    "    if display:\n",
    "        plot.figure(figsize=(10, 5))\n",
    "        plot.title('Keypoint Matches')\n",
    "\n",
    "    if not regions_one['entire']['keypoints'] or not regions_two['entire']['keypoints']:\n",
    "        print(\"KeyPoints not found in one or both images for entire region!!!\")\n",
    "        return 0\n",
    "\n",
    "    matches = find_matches(regions_one['entire'], regions_two['entire'], ratio_threshold, angle_standard_deviation, distance_standard_deviation)\n",
    "    if display:\n",
    "        if matches:\n",
    "            matches_to_draw = [[m] for m in matches]\n",
    "            matched_image = cv2.drawMatchesKnn(\n",
    "                regions_one['entire']['image'], regions_one['entire']['keypoints'],\n",
    "                regions_two['entire']['image'], regions_two['entire']['keypoints'],\n",
    "                matches_to_draw, None, flags=2)\n",
    "            matched_image_rgb = cv2.cvtColor(matched_image, cv2.COLOR_BGR2RGB)\n",
    "            plot.imshow(matched_image_rgb)\n",
    "            plot.title(f'Matches in Entire Region')\n",
    "            plot.axis('off')\n",
    "        else:\n",
    "            print(\"No matches to draw for entire region\")\n",
    "\n",
    "        plot.show()\n",
    "    print(f\"Total matches found: {len(matches)}\") \n",
    "\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c758b9b",
   "metadata": {},
   "source": [
    "### Fonction : find_matches\n",
    "Filtre les correspondances entre les points clés des deux régions en évaluant la cohérence géométrique basée sur des seuils de ratio, d'angle et de distance. Cette analyse détaillée assure que seules les correspondances les plus fiables sont conservées, utilisant des critères précis pour évaluer la similitude des points clés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50985a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_matches(region_one, region_two, ratio_threshold, angle_deviation_threshold, distance_deviation_threshold):    \n",
    "    if not region_one['keypoints'] or not region_two['keypoints']:\n",
    "        print(\"KeyPoints not found in one of region_x['keypoints'] !!!\")\n",
    "        return []\n",
    "\n",
    "    matcher = cv2.BFMatcher()\n",
    "    raw_matches = matcher.knnMatch(region_one['descriptors'], region_two['descriptors'], k=2)\n",
    "    print(f\"Raw matches found: {len(raw_matches)}\")\n",
    "    kp1 = region_one['keypoints']\n",
    "    kp2 = region_two['keypoints']\n",
    "\n",
    "    distance_diff_one = region_one['outer_circle'][2] - region_one['inner_circle'][2]\n",
    "    distance_diff_two = region_two['outer_circle'][2] - region_two['inner_circle'][2]\n",
    "\n",
    "    angle_differences = []\n",
    "    distance_differences = []\n",
    "    filtered_matches = []\n",
    "    for m,n in raw_matches:\n",
    "        if (m.distance/n.distance) > ratio_threshold:\n",
    "            continue\n",
    "        \n",
    "        x1,y1 = kp1[m.queryIdx].pt\n",
    "        x2,y2 = kp2[m.trainIdx].pt\n",
    "\n",
    "        angle_one = calculate_angle(\n",
    "                x1,y1,\n",
    "                region_one['inner_circle'][0],\n",
    "                region_one['inner_circle'][1])\n",
    "        angle_two = calculate_angle(\n",
    "                x2,y2,\n",
    "                region_two['inner_circle'][0],\n",
    "                region_two['inner_circle'][1])\n",
    "        angle_difference = angle_one - angle_two\n",
    "        angle_differences.append(angle_difference)\n",
    "\n",
    "        distance_one = compute_distance(x1,y1,\n",
    "                          region_one['inner_circle'][0],\n",
    "                          region_one['inner_circle'][1])\n",
    "        distance_one = distance_one - region_one['inner_circle'][2]\n",
    "        distance_one = distance_one / distance_diff_one\n",
    "        \n",
    "        distance_two = compute_distance(x2,y2,\n",
    "                          region_two['inner_circle'][0],\n",
    "                          region_two['inner_circle'][1])\n",
    "        distance_two = distance_two - region_two['inner_circle'][2]\n",
    "        distance_two = distance_two / distance_diff_two\n",
    "\n",
    "        distance_difference = distance_one - distance_two\n",
    "        distance_differences.append(distance_difference)\n",
    "        \n",
    "        filtered_matches.append(m)\n",
    "\n",
    "    if filtered_matches:\n",
    "        median_angle_difference = compute_median(angle_differences)\n",
    "        median_distance_difference = compute_median(distance_differences)\n",
    "        for match in filtered_matches[:]:\n",
    "            x1,y1 = kp1[match.queryIdx].pt\n",
    "            x2,y2 = kp2[match.trainIdx].pt\n",
    "\n",
    "            angle_one = calculate_angle(\n",
    "                x1,y1,\n",
    "                region_one['inner_circle'][0],\n",
    "                region_one['inner_circle'][1])\n",
    "            angle_two = calculate_angle(\n",
    "                x2,y2,\n",
    "                region_two['inner_circle'][0],\n",
    "                region_two['inner_circle'][1])\n",
    "            angle_difference = angle_one - angle_two\n",
    "\n",
    "            within_angle_limits = \\\n",
    "                (angle_difference > median_angle_difference - angle_deviation_threshold and \\\n",
    "                 angle_difference < median_angle_difference + angle_deviation_threshold)\n",
    "\n",
    "            distance_one = compute_distance(x1,y1,\n",
    "                              region_one['inner_circle'][0],\n",
    "                              region_one['inner_circle'][1])\n",
    "            distance_one = distance_one - region_one['inner_circle'][2]\n",
    "            distance_one = distance_one / distance_diff_one\n",
    "        \n",
    "            distance_two = compute_distance(x2,y2,\n",
    "                              region_two['inner_circle'][0],\n",
    "                              region_two['inner_circle'][1])\n",
    "            distance_two = distance_two - region_two['inner_circle'][2]\n",
    "            distance_two = distance_two / distance_diff_two\n",
    "\n",
    "            distance_difference = distance_one - distance_two\n",
    "            within_distance_limits = (distance_difference > median_distance_difference - distance_deviation_threshold and \\\n",
    "                         distance_difference < median_distance_difference + distance_deviation_threshold)\n",
    "                \n",
    "            if within_angle_limits and within_distance_limits:\n",
    "                continue\n",
    "\n",
    "            filtered_matches.remove(match)\n",
    "\n",
    "    return filtered_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c6a00",
   "metadata": {},
   "source": [
    "###  Fonctions Mathématiques Utiles\n",
    "Ces fonctions fournissent des calculs essentiels pour l'analyse et le traitement d'images:\n",
    "\n",
    "- **calculate_angle(x1, y1, x2, y2):** Calcule l'angle en degrés entre deux points.\n",
    "- **compute_distance(x1, y1, x2, y2):** Détermine la distance euclidienne entre deux points.\n",
    "- **compute_mean(values):** Calcule la moyenne d'une liste de valeurs numériques.\n",
    "- **compute_median(values):** Trouve la valeur médiane d'une liste, offrant une mesure centrale robuste.\n",
    "- **compute_standard_deviation(values):** Calcule l'écart type pour mesurer la variation ou la dispersion des valeurs autour de la moyenne.\n",
    "\n",
    "Ces outils sont cruciaux pour les opérations géométriques et l'analyse statistique dans le traitement des données d'image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed57970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    return math.degrees(math.atan2(-(y2-y1),(x2-x1)))\n",
    "\n",
    "def compute_distance(x1, y1, x2, y2):\n",
    "    distance = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    return distance\n",
    "\n",
    "def compute_mean(values):\n",
    "    total = 0.0\n",
    "    for value in values:\n",
    "        total += value\n",
    "    return total/len(values)\n",
    "\n",
    "def compute_median(values):\n",
    "    return np.median(np.array(values))\n",
    "\n",
    "def compute_standard_deviation(values):\n",
    "    if not values:\n",
    "        print('Error: empty list parameter in compute_standard_deviation() !')\n",
    "        return None, None\n",
    "    mean_value = compute_mean(values)\n",
    "    sum_of_squares = 0.0\n",
    "    for value in values:\n",
    "        sum_of_squares += (value - mean_value) ** 2\n",
    "    return mean_value, math.sqrt(sum_of_squares/len(values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5aa65",
   "metadata": {},
   "source": [
    "### Fonctions : serialize_keypoints et deserialize_keypoints\n",
    "Ces fonctions gèrent la sérialisation et la désérialisation des points clés utilisés dans les algorithmes SIFT pour faciliter le stockage et la comparaison:\n",
    "\n",
    "- **serialize_keypoints(keypoints):** Convertit une liste de points clés en une structure de données sérialisée, préparant les données pour un stockage efficace dans un fichier pickle.\n",
    "- **deserialize_keypoints(serialized_keypoints):** Reconstruit les points clés à partir de leur forme sérialisée, permettant la comparaison des données d'image stockées avec une nouvelle image test pour la reconnaissance diris.\n",
    "\n",
    "Ces fonctions sont essentielles pour crypter les points de données de SIFT lors de l'enregistrement dans une base de données et pour décrypter ces points lors de la comparaison avec une nouvelle image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b256d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def serialize_keypoints(keypoints):\n",
    "    return [{'pt': keypoint.pt, 'size': keypoint.size, 'angle': keypoint.angle,\n",
    "             'response': keypoint.response, 'octave': keypoint.octave, 'class_id': keypoint.class_id}\n",
    "            for keypoint in keypoints]\n",
    "def deserialize_keypoints(serialized_keypoints):\n",
    "    return [cv2.KeyPoint(x=kp['pt'][0], y=kp['pt'][1], size=kp['size'], angle=kp['angle'],\n",
    "                         response=kp['response'], octave=kp['octave'], class_id=kp['class_id'])\n",
    "            for kp in serialized_keypoints]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e183555",
   "metadata": {},
   "source": [
    "###  Fonction : inspect_region_information\n",
    "Affiche des informations essentielles sur une région d'image traitée, notamment les dimensions de l'image et le nombre de points clés détectés. Cette fonction facilite le diagnostic rapide de l'état des données de région après le traitement, ce qui est crucial pour le débogage et l'analyse de performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inspect_region_information(regions):\n",
    "    data = regions['entire']\n",
    "    print(\"Region: Entire\")\n",
    "    print(f\"Image dimensions: {data['image'].shape}\")\n",
    "    print(f\"Number of keypoints: {len(data['keypoints'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cac9f",
   "metadata": {},
   "source": [
    "### Fonction : preprocess_and_serialize\n",
    "Crée une base de données sérialisée pour la reconnaissance d'images à partir d'un chemin de données spécifié. Pour chaque individu, la fonction sélectionne la première image, extrait les régions pertinentes de l'iris, sérialise les points clés et enregistre les données sérialisées dans un fichier pickle dans le répertoire de sortie. Cela permet de préparer les données nécessaires pour la reconnaissance ultérieure.\n",
    "\n",
    "**Paramètres :**\n",
    "- `dataset_path`: Chemin vers le répertoire contenant les images brutes.\n",
    "- `output_path`: Chemin vers le répertoire où les données sérialisées seront sauvegardées.\n",
    "\n",
    "**Étapes :**\n",
    "1. Parcourt chaque dossier d'individu dans le répertoire de données.\n",
    "2. Sélectionne la première image de chaque dossier.\n",
    "3. Extrait les régions de l'iris et sérialise les points clés.\n",
    "4. Sauvegarde les données sérialisées dans un fichier pickle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_serialize(dataset_path, output_path):\n",
    "    for person_id in sorted(os.listdir(dataset_path)):\n",
    "        person_path = os.path.join(dataset_path, person_id)\n",
    "        if os.path.isdir(person_path):\n",
    "            images = sorted(os.listdir(person_path))\n",
    "            if images:  \n",
    "                image_name = images[0]  \n",
    "                image_path = os.path.join(person_path, image_name)\n",
    "                region_data = extract_regions(image_path)\n",
    "                if region_data:\n",
    "                    region_data['entire']['keypoints'] = serialize_keypoints(region_data['entire']['keypoints'])\n",
    "                    serialized_file_path = os.path.join(output_path, f\"{person_id}_{image_name}.pkl\")\n",
    "                    with open(serialized_file_path, 'wb') as f:\n",
    "                        pickle.dump(region_data, f)\n",
    "                        print(f\"Serialized data for {person_id} saved to {serialized_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062045d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "dataset_path = 'A_Data\\\\Raw_Data'\n",
    "output_path = 'B_SIFT_knn_bfm\\\\3_DATA_modele_data_base'\n",
    "\n",
    "#preprocess_and_serialize(dataset_path, output_path)\n",
    "\n",
    "\n",
    "serialized_data_path ='C:\\\\Users\\\\pc\\\\Desktop\\\\Backend\\\\B_SIFT_knn_bfm\\\\3_DATA_modele_data_base'\n",
    "test_image_path = 'C:\\\\Users\\\\pc\\\\Desktop\\\\Backend\\\\A_Data\\\\Raw_Data\\\\001\\\\S6001S02.jpg'\n",
    "raw_data = 'C:\\\\Users\\\\pc\\\\Desktop\\\\Backend\\\\A_Data\\\\Raw_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dabc09",
   "metadata": {},
   "source": [
    "### Fonction pour effectuer une comparaison visuelle entre l'image test et l'image de la classe prédite\n",
    "\n",
    "Cette fonction, `perform_visual_comparison`, est conçue pour valider visuellement la précision de la prédiction du modèle en comparant limage  avec une image de référence de la classe prédite, en utilisant des données sérialisées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca81ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_visual_comparison(predicted_class, raw_data_path, serialized_data_path, test_regions):\n",
    "    # Load the first image from the predicted class's raw data folder\n",
    "    predicted_class_folder = os.path.join(raw_data_path, predicted_class)\n",
    "    predicted_image_path = os.path.join(predicted_class_folder, os.listdir(predicted_class_folder)[0])\n",
    "    \n",
    "    # Deserialize the predicted class structure\n",
    "    for file in os.listdir(serialized_data_path):\n",
    "        if file.startswith(predicted_class + \"_\"):\n",
    "            serialized_file_path = os.path.join(serialized_data_path, file)\n",
    "            break\n",
    "\n",
    "    with open(serialized_file_path, 'rb') as f:\n",
    "        serialized_data = pickle.load(f)\n",
    "    serialized_data['entire']['keypoints'] = deserialize_keypoints(serialized_data['entire']['keypoints'])\n",
    "\n",
    "    # Use the deserialized keypoints and descriptors to match against the test image\n",
    "    match_all_regions(test_regions, serialized_data, 0.8, 10, 0.15, display=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e954c",
   "metadata": {},
   "source": [
    "### Fonction : find_best_match\n",
    "Compare une image de test avec des données sérialisées stockées pour identifier la meilleure correspondance. Cette fonction extrait les régions de l'image de test, désérialise les données de points clés pour chaque entrée de la base de données, et utilise `match_all_regions` pour compter et comparer les correspondances. Elle rapporte la meilleure correspondance en fonction du nombre maximum de correspondances trouvées, facilitant ainsi la reconnaissance ou la vérification d'identité.\n",
    "et cette fonction utilise perform_visual_comparison pour visualiser la comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_match(test_image_path, serialized_data_path):\n",
    "    test_data = extract_regions(test_image_path)\n",
    "\n",
    "\n",
    "    max_matches = 0\n",
    "    best_match = None\n",
    "        \n",
    "    for serialized_file in os.listdir(serialized_data_path):\n",
    "            with open(os.path.join(serialized_data_path, serialized_file), 'rb') as f:\n",
    "                person_data = pickle.load(f)\n",
    "                person_data['entire']['keypoints'] = deserialize_keypoints(person_data['entire']['keypoints'])\n",
    "                matches = match_all_regions(test_data, person_data, 0.8, 10, 0.15, display=False)\n",
    "                \n",
    "                if matches > max_matches:\n",
    "                    max_matches = matches\n",
    "                    best_match = serialized_file\n",
    "        \n",
    "    if best_match:\n",
    "            best_match = best_match.split('_')[0]\n",
    "            perform_visual_comparison(best_match, raw_data, serialized_data_path, test_data)\n",
    "\n",
    "            print(f\"The test image matches best with {best_match} with {max_matches} matches.\")\n",
    "            return best_match\n",
    "\n",
    "    else:\n",
    "            print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3fe12",
   "metadata": {},
   "source": [
    "### tester une seul image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05384639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "serialized_data_path ='B_SIFT_knn_bfm\\\\3_DATA_modele_data_base'\n",
    "test_image_path = 'A_Data\\\\Raw_Data\\\\001\\\\S6001S02.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id = find_best_match(test_image_path, serialized_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3f39d",
   "metadata": {},
   "source": [
    "### Fonction : testing_and_accuracy_calculation\n",
    "Cette fonction teste de nouvelles images qui n'étaient pas sauvegardées dans la base de données pour vérifier leur précision(classes) et la precision totale. Après le test, la précision était de 98 %, où chaque personne avait 1 image traitée et cryptée dans la base de données, et 9 images étaient utilisées pour les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def testing_and_accuracy_calculation(dataset_path,base):\n",
    "    i = [0] * 100 \n",
    "    j=0\n",
    "    accuracies = []\n",
    "    total_correct_matches = 0\n",
    "    total_images = 0\n",
    "\n",
    "    for person_id in sorted(os.listdir(dataset_path)):\n",
    "        person_path = os.path.join(dataset_path, person_id)\n",
    "        if os.path.isdir(person_path):\n",
    "            images = sorted(os.listdir(person_path))\n",
    "            if images:\n",
    "                for image in images[1:]:  \n",
    "                  image_name = image  \n",
    "                  image_path = os.path.join(person_path, image_name)\n",
    "                  matched_id = find_best_match(image_path, base)\n",
    "                  if matched_id == person_id:\n",
    "                     i[j]=i[j]+1\n",
    "                     continue\n",
    "            correct_matches = i[j]\n",
    "            total_correct_matches += correct_matches\n",
    "            total_images += 9\n",
    "\n",
    "            accuracy = correct_matches /9\n",
    "            accuracies.append((person_id, accuracy))\n",
    "        j=j+1   \n",
    "\n",
    "    overall_accuracy = total_correct_matches / total_images if total_images > 0 else 0\n",
    "    for person_id, accuracy in accuracies:\n",
    "        print(f\"Person {person_id}: Accuracy = {accuracy:.2%}\")\n",
    "    print(f\"Overall Accuracy = {overall_accuracy:.2%}\")\n",
    "    \n",
    "\n",
    "               \n",
    "#testing_and_accuracy_calculation('A_Data\\\\Raw_Data','B_SIFT_knn_bfm\\\\3_DATA_modele_data_base')      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
