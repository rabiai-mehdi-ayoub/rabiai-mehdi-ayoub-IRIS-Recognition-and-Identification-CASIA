{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3b146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import inspect\n",
    "from matplotlib import pyplot as plot\n",
    "import pandas as pd\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.filters.rank import equalize\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1a21a",
   "metadata": {},
   "source": [
    "### Remarque : \n",
    "#### Le préprocessing des données de la dataset complète a deja été fait , il coutera cher en temps de calcul de le refaire ici ( 5h ~ 7h ), c'est pour cela que je vous propose de ne pas executer les cellules de code qui font le préprocessing des données et de se contenter de la cellule qui charge les données prétraitées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e56279",
   "metadata": {},
   "source": [
    "### Fonction : locate_iris_boundaries\n",
    "Détecte dynamiquement les limites internes et externes de l'iris en ajustant progressivement les paramètres de recherche en fonction des résultats initiaux.\n",
    "(La détection est effectuée dans d'autres fonctions. Cette fonction utilise les autres fonctions afin de détecter les bordures et ajuste les paramètres jusqu'à ce que les limites soient trouvées.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1990c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_iris_boundaries(image, display=False):\n",
    "    inner_circle = detect_inner_circle(image)\n",
    "\n",
    "    if not inner_circle:\n",
    "        print('ERROR: Inner circle not found!')\n",
    "        return None, None\n",
    "\n",
    "    radius_expansion = int(math.ceil(inner_circle[2]*1.5))\n",
    "    expansion_factor = 0.25\n",
    "    range_center = int(math.ceil(inner_circle[2]*expansion_factor)) \n",
    "    outer_circle = detect_outer_circle(\n",
    "                        image, inner_circle, range_center, radius_expansion)\n",
    "\n",
    "    while(not outer_circle and expansion_factor <= 0.7):\n",
    "        expansion_factor += 0.05\n",
    "        print('Searching outer iris circle with expansion factor ' + str(expansion_factor))\n",
    "\n",
    "        range_center = int(math.ceil(inner_circle[2]*expansion_factor))\n",
    "        outer_circle = detect_outer_circle(image, inner_circle,\n",
    "                                        range_center, radius_expansion)\n",
    "    if not outer_circle:\n",
    "        print('ERROR: Outer iris circle not found!')\n",
    "        return None, None\n",
    "    \n",
    "    if display:\n",
    "        color_image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "        draw_detected_circles(color_image, inner_circle, outer_circle,\n",
    "                     range_center, radius_expansion)\n",
    "        cv2.imshow('iris boundaries', color_image)\n",
    "        char = cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return inner_circle, outer_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21878b38",
   "metadata": {},
   "source": [
    "### Fonction : detect_inner_circle\n",
    "Détecte le cercle intérieur de l'iris en appliquant des filtres et en ajustant les seuils de manière dynamique pour optimiser la détection des cercles via la transformation de Hough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a41ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_inner_circle(image):\n",
    "    def extract_edges(processed_image):\n",
    "        edges = cv2.Canny(processed_image, 20, 100)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "        blur_size = 2 * random.randrange(5, 11) + 1\n",
    "        edges = cv2.GaussianBlur(edges, (blur_size, blur_size), 0)\n",
    "        return edges\n",
    "\n",
    "    circle_param1 = 200  # High threshold for Canny\n",
    "    circle_param2 = 120  # Accumulator threshold for circle detection\n",
    "    candidate_circles = []\n",
    "    while(circle_param2 > 35 and len(candidate_circles) < 100):\n",
    "        for median_filter_size, threshold in [(m, t) for m in [3, 5, 7] for t in [20, 25, 30, 35, 40, 45, 50, 55, 60]]:\n",
    "            # Apply median blur\n",
    "            blurred = cv2.medianBlur(image, 2 * median_filter_size + 1)\n",
    "\n",
    "            # Apply threshold\n",
    "            _, binary_image = cv2.threshold(blurred, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            # Fill contours\n",
    "            contours, _ = cv2.findContours(binary_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            filled_contours = cv2.drawContours(binary_image, contours, -1, (255), -1)\n",
    "\n",
    "            # Extract edges\n",
    "            edges = extract_edges(binary_image)\n",
    "\n",
    "            # Detect circles using Hough transform\n",
    "            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 1, np.array([]), circle_param1, circle_param2)\n",
    "            if circles is not None and circles.size > 0:\n",
    "                # Convert the circle parameters to integers\n",
    "                circles = np.round(circles[0, :]).astype(\"int\")\n",
    "                for circle in circles:\n",
    "                    candidate_circles.append(circle)\n",
    "\n",
    "        circle_param2 = circle_param2 - 1\n",
    "\n",
    "    if len(candidate_circles) == 0:\n",
    "        print(\"No inner circles detected.\")\n",
    "        return None\n",
    "\n",
    "    return calculate_average_circle(candidate_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156620",
   "metadata": {},
   "source": [
    "### Fonction : calculate_average_circle\n",
    "Calcule et retourne les coordonnées moyennes et le rayon moyen à partir d'une liste de cercles détectés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943dcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_average_circle(circles):\n",
    "    if not circles:\n",
    "        return\n",
    "    average_x = int(np.mean([c[0] for c in circles]))\n",
    "    average_y = int(np.mean([c[1] for c in circles]))\n",
    "    average_radius = int(np.mean([c[2] for c in circles]))\n",
    "\n",
    "    return average_x, average_y, average_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2018e",
   "metadata": {},
   "source": [
    "### Fonction : identify_optimal_radius\n",
    "Identifie le rayon optimal en minimisant la distance totale par rapport aux autres rayons dans la liste, permettant une sélection plus précise du cercle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a99e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_optimal_radius(circle_list):\n",
    "    optimal_circle = None\n",
    "    minimum_distance = None\n",
    "    reference_circles = circle_list[:]\n",
    "    comparison_circles = circle_list[:]\n",
    "    for current_circle in reference_circles:\n",
    "        total_distance = 0\n",
    "        for compared_circle in comparison_circles:\n",
    "            total_distance += math.fabs(float(current_circle[2]) - float(compared_circle[2]))\n",
    "        if not minimum_distance or total_distance < minimum_distance:\n",
    "            minimum_distance = total_distance\n",
    "            optimal_circle = current_circle\n",
    "    return optimal_circle[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63d45e",
   "metadata": {},
   "source": [
    "### Fonction : detect_outer_circle\n",
    "Détecte dynamiquement le cercle extérieur de l'iris en analysant les bords de l'image traitée. La fonction utilise plusieurs tailles de flou médian et des seuils de détection ajustés itérativement pour identifier les cercles par transformation de Hough. La détection continue jusqu'à ce que le nombre cible de cercles soit atteint ou que les seuils de détection soient épuisés, tout en vérifiant que les cercles détectés se trouvent bien à l'extérieur du cercle intérieur mais dans les limites spécifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60996ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_outer_circle(image, inner_circle, center_range, radius_range):\n",
    "    def extract_edges(processed_image, upper_threshold):\n",
    "        lower_threshold = 0  # Fixed low threshold for Canny\n",
    "        edges = cv2.Canny(processed_image, lower_threshold, upper_threshold, apertureSize=5)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "        blur_size = 2 * random.randrange(5,11) + 1\n",
    "        edges = cv2.GaussianBlur(edges,(blur_size,blur_size),0)\n",
    "        return edges\n",
    "\n",
    "    def find_circles(hough_threshold, median_sizes, edge_thresholds):\n",
    "        detected_circles = []\n",
    "        for median_size, upper_threshold in [(m, t) for m in median_sizes for t in edge_thresholds]:\n",
    "            # Apply median blur\n",
    "            median_blurred = cv2.medianBlur(image, 2 * median_size + 1)\n",
    "\n",
    "            # Extract edges\n",
    "            edges = extract_edges(median_blurred, upper_threshold)\n",
    "\n",
    "            # Detect circles using Hough transform\n",
    "            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                                       param1=200, param2=hough_threshold, minRadius=0, maxRadius=0)\n",
    "            if circles is not None and circles.size > 0:\n",
    "                # Convert the circle parameters to integers\n",
    "                circles = np.round(circles[0, :]).astype(\"int\")\n",
    "                for (col, row, radius) in circles:\n",
    "                    if within_circle(inner_circle[0], inner_circle[1], center_range, col, row) and radius > radius_range:\n",
    "                        detected_circles.append((col, row, radius))\n",
    "        return detected_circles\n",
    "\n",
    "    circle_param2 = 120  # Starting threshold for HoughCircles\n",
    "    all_circles = []\n",
    "    while(circle_param2 > 40 and len(all_circles) < 50):\n",
    "        circles = find_circles(\n",
    "                        circle_param2, [8,10,12,14,16,18,20], [430,480,530])\n",
    "        if circles:\n",
    "            all_circles += circles\n",
    "        circle_param2 = circle_param2 -1\n",
    "\n",
    "    if not all_circles:\n",
    "        print(\"Alternative strategy for detecting outer iris circle\")\n",
    "        circle_param2 = 120\n",
    "        while(circle_param2 > 40 and len(all_circles) < 50):\n",
    "            circles = find_circles(\n",
    "                            circle_param2, [3,5,7,21,23,25], [430,480,530])\n",
    "            if circles:\n",
    "                all_circles += circles\n",
    "            circle_param2 = circle_param2 -1\n",
    "\n",
    "    if not all_circles:\n",
    "        return\n",
    "\n",
    "    color_image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "    refined_circles = refine_circle_selection(all_circles)\n",
    "\n",
    "    return calculate_average_circle(refined_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608576b",
   "metadata": {},
   "source": [
    "### Fonction : within_circle\n",
    "Vérifie si un point donné se trouve à l'intérieur du rayon d'un cercle spécifié, en utilisant la distance entre le centre du cercle et le point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def within_circle(circle_col, circle_row, circle_radius, point_col, point_row):\n",
    "    return compute_distance(circle_col, circle_row, point_col, point_row) <= circle_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5992e",
   "metadata": {},
   "source": [
    "### Fonction : refine_circle_selection\n",
    "Affine la sélection de cercles détectés en filtrant ceux qui s'écartent significativement des moyennes calculées pour les positions et rayons. cet fonction Utilise des écarts types pour définir les seuils d'acceptation, en éliminant les cercles qui ne correspondent pas aux critères statistiques de cohérence des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_circle_selection(circles):\n",
    "    if not circles:\n",
    "        print('Error: No circles found in refine_circle_selection() !')\n",
    "        return []\n",
    "    center_x_mean, center_x_dev = compute_standard_deviation([int(i[0]) for i in circles])\n",
    "    center_y_mean, center_y_dev = compute_standard_deviation([int(i[1]) for i in circles])\n",
    "    refined = []\n",
    "    positions = []\n",
    "    unrefined = []\n",
    "    deviation_multiplier = 1.5 \n",
    "    for circle in circles[:]:\n",
    "        if circle[0] < center_x_mean - deviation_multiplier*center_x_dev or \\\n",
    "           circle[0] > center_x_mean + deviation_multiplier*center_x_dev or \\\n",
    "           circle[1] < center_y_mean - deviation_multiplier*center_y_dev or \\\n",
    "           circle[1] > center_y_mean + deviation_multiplier*center_y_dev:\n",
    "            unrefined.append(circle)\n",
    "        else:\n",
    "            positions.append(circle)\n",
    "    if len([float(c[2]) for c in positions]) < 3:\n",
    "        refined = positions\n",
    "    else:\n",
    "        optimal_radius = identify_optimal_radius(positions)\n",
    "        mean_radius, radius_deviation = compute_standard_deviation(\n",
    "                                    [float(c[2]) for c in positions])\n",
    "        max_radius = optimal_radius + radius_deviation\n",
    "        min_radius = optimal_radius - radius_deviation\n",
    "        for circle in positions:\n",
    "            if circle[2] < min_radius or \\\n",
    "               circle[2] > max_radius:\n",
    "                unrefined.append(circle)\n",
    "            else:\n",
    "                refined.append(circle)\n",
    "\n",
    "    return refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d5bce",
   "metadata": {},
   "source": [
    "### Fonction : draw_detected_circles\n",
    "Dessine les cercles détectés sur une image colorée, y compris les cercles internes et externes de l'iris, ainsi que les limites spécifiques de portée et de rayon si elles sont fournies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_detected_circles(colored_image, inner_circle, outer_circle,\n",
    "                 center_range=None, radius_range=None):\n",
    "    # draw the inner circle\n",
    "    cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), inner_circle[2],\n",
    "                     (0,0,255),1)\n",
    "    # draw the center of the inner circle\n",
    "    cv2.circle(colored_image,(inner_circle[0],inner_circle[1]),1,(0,0,255),1)\n",
    "    if center_range:\n",
    "        # draw outer circle center range limit\n",
    "        cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), center_range,\n",
    "                         (0,255,255),1)\n",
    "    if radius_range:\n",
    "        # draw outer circle radius range limit\n",
    "        cv2.circle(colored_image,(inner_circle[0], inner_circle[1]), radius_range,\n",
    "                         (0,255,255),1)\n",
    "    # draw the outer circle\n",
    "    cv2.circle(colored_image, (outer_circle[0], outer_circle[1]), \n",
    "               outer_circle[2],(0,255,0),1)\n",
    "    # draw the center of the outer circle\n",
    "    cv2.circle(colored_image, (outer_circle[0], outer_circle[1]), \n",
    "               1,(0,255,0),1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c6a00",
   "metadata": {},
   "source": [
    "###  Fonctions Mathématiques Utiles\n",
    "Ces fonctions fournissent des calculs essentiels pour l'analyse et le traitement d'images:\n",
    "\n",
    "- **calculate_angle(x1, y1, x2, y2):** Calcule l'angle en degrés entre deux points.\n",
    "- **compute_distance(x1, y1, x2, y2):** Détermine la distance euclidienne entre deux points.\n",
    "- **compute_mean(values):** Calcule la moyenne d'une liste de valeurs numériques.\n",
    "- **compute_median(values):** Trouve la valeur médiane d'une liste, offrant une mesure centrale robuste.\n",
    "- **compute_standard_deviation(values):** Calcule l'écart type pour mesurer la variation ou la dispersion des valeurs autour de la moyenne.\n",
    "\n",
    "Ces outils sont cruciaux pour les opérations géométriques et l'analyse statistique dans le traitement des données d'image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed57970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    return math.degrees(math.atan2(-(y2-y1),(x2-x1)))\n",
    "\n",
    "def compute_distance(x1, y1, x2, y2):\n",
    "    distance = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    return distance\n",
    "\n",
    "def compute_mean(values):\n",
    "    total = 0.0\n",
    "    for value in values:\n",
    "        total += value\n",
    "    return total/len(values)\n",
    "\n",
    "def compute_median(values):\n",
    "    return np.median(np.array(values))\n",
    "\n",
    "def compute_standard_deviation(values):\n",
    "    if not values:\n",
    "        print('Error: empty list parameter in compute_standard_deviation() !')\n",
    "        return None, None\n",
    "    mean_value = compute_mean(values)\n",
    "    sum_of_squares = 0.0\n",
    "    for value in values:\n",
    "        sum_of_squares += (value - mean_value) ** 2\n",
    "    return mean_value, math.sqrt(sum_of_squares/len(values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5ca06",
   "metadata": {},
   "source": [
    "### Fonction : IrisNormalization\n",
    "Normalise la région de l'iris en convertissant la région annulaire entre les cercles interne et externe de l'iris en une image rectangulaire de dimensions fixes. Cette fonction crée une cartographie du contour de l'iris à une image de 64x512 pixels, utilisant l'interpolation pour ajuster les données des pixels entre les frontières interne et externe. Cela facilite une comparaison plus uniforme et précise des caractéristiques de l'iris dans des images de reconnaissance.\n",
    "\n",
    "**Paramètres:**\n",
    "- `image`: Image d'entrée contenant l'iris.\n",
    "- `inner_circle`: Coordonnées et rayon du cercle interne de l'iris.\n",
    "- `outer_circle`: Coordonnées et rayon du cercle externe de l'iris.\n",
    "\n",
    "**Retourne:**\n",
    "- `res_image`: Image de l'iris normalisée avec des dimensions de 64x512 pixels, prête pour l'analyse et la reconnaissance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IrisNormalization(image,inner_circle,outer_circle ):\n",
    "    localized_img=image\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris=np.zeros(shape=(64,512))\n",
    "    inner_y=inner_circle[0]  #height\n",
    "    inner_x=inner_circle[1]  #width\n",
    "    outer_y=outer_circle[0]\n",
    "    outer_x=outer_circle[1]\n",
    "    angle=2.0*math.pi/col\n",
    "    inner_boundary_x = np.zeros(shape=(1,col))\n",
    "    inner_boundary_y = np.zeros(shape=(1,col))\n",
    "    outer_boundary_x = np.zeros(shape=(1,col))\n",
    "    outer_boundary_y = np.zeros(shape=(1,col))\n",
    "    for j in range(col):\n",
    "\n",
    "\n",
    "        inner_boundary_x[0][j]=inner_circle[0]+inner_circle[2]*math.cos(angle*(j))\n",
    "        inner_boundary_y[0][j]=inner_circle[1]+inner_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "        outer_boundary_x[0][j]=outer_circle[0]+outer_circle[2]*math.cos(angle*(j))\n",
    "        outer_boundary_y[0][j]=outer_circle[1]+outer_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "    for j in range (512):\n",
    "        for i in range (64):\n",
    "             normalized_iris[i][j]=localized_img[min(int(int(inner_boundary_y[0][j])\n",
    "                                   +(int(outer_boundary_y[0][j])-int(inner_boundary_y[0][j]))*(i/64.0)),localized_img.shape[0]-1)][min(int(int(inner_boundary_x[0][j])\n",
    "                                   +(int(outer_boundary_x[0][j])-int(inner_boundary_x[0][j]))\n",
    "                                   *(i/64.0)),localized_img.shape[1]-1)]\n",
    "\n",
    "    res_image=255-normalized_iris\n",
    "    return res_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cde0c3",
   "metadata": {},
   "source": [
    "### Fonction : ImageEnhancement\n",
    "Améliore l'image normalisée de l'iris pour augmenter la clarté et le contraste des caractéristiques importantes. La fonction convertit l'image en entier 8 bits, applique une égalisation d'histogramme locale utilisant un élément structurant en forme de disque pour mieux répartir l'intensité lumineuse, et extrait ensuite une région d'intérêt (ROI) pour réduire les distractions et se concentrer sur les parties les plus pertinentes de l'iris.\n",
    "\n",
    "**Paramètres:**\n",
    "- `normalized_iris`: Image de l'iris normalisée préparée pour l'amélioration.\n",
    "\n",
    "**Retourne:**\n",
    "- `roi`: Région d'intérêt de l'image améliorée, plus adaptée à l'analyse ultérieure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageEnhancement(normalized_iris):\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris = normalized_iris.astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    enhanced_image=normalized_iris\n",
    "     \n",
    "    enhanced_image = equalize(enhanced_image, disk(32))\n",
    "    \n",
    "    roi = enhanced_image[0:48,:]\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420668f0",
   "metadata": {},
   "source": [
    "### Fonction : preprocess\n",
    "Traite une image pour l'analyse de l'iris, en commençant par la lecture de l'image, la conversion en niveaux de gris, la détection des contours de l'iris et de la pupille, la normalisation de la région de l'iris, et enfin l'amélioration de cette région pour une analyse détaillée. La fonction visualise également les contours détectés sur l'image initiale pour vérification, puis extrait et améliore la région normalisée pour obtenir une région d'intérêt (ROI) optimale pour l'extraction de caractéristiques.\n",
    "\n",
    "**Processus:**\n",
    "1. **Lecture et conversion:** L'image est lue et convertie en niveaux de gris.\n",
    "2. **Détection des contours:** Utilise `locate_iris_boundaries` pour identifier les cercles de l'iris et de la pupille.\n",
    "3. **Visualisation des contours:** Dessine les contours de l'iris et de la pupille sur l'image pour vérification.\n",
    "4. **Normalisation de l'iris:** Applique `IrisNormalization` pour transformer la région annulaire de l'iris en une forme rectangulaire standard.\n",
    "5. **Amélioration de l'image:** Utilise `ImageEnhancement` pour améliorer la clarté et le contraste de l'image normalisée.\n",
    "\n",
    "**Paramètres:**\n",
    "- `image`: Chemin de l'image à traiter.\n",
    "\n",
    "**Retourne:**\n",
    "- `ROI`: Région d'intérêt de l'image améliorée, prête pour l'extraction de caractéristiques et l'analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    imagep = cv2.imread(image)                \n",
    "    eye = cv2.cvtColor(imagep, cv2.COLOR_BGR2GRAY)\n",
    "    outer , inner = locate_iris_boundaries(eye)\n",
    "    x_iris,y_iris,r_iris = outer\n",
    "    x_pupil,y1_pupil,r1_pupil = inner\n",
    "    dra1 = eye.copy()\n",
    "    cv2.circle(dra1, (x_iris, y_iris), r_iris, color=(255, 0, 0), thickness=3)\n",
    "    cv2.circle(dra1, (x_pupil, y1_pupil), r1_pupil, color=(255, 0, 0), thickness=3)\n",
    "    iris, pupil = outer,inner\n",
    "    normalized = IrisNormalization(eye, pupil, iris)\n",
    "    ROI = ImageEnhancement(normalized)\n",
    "    return ROI\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaae017",
   "metadata": {},
   "source": [
    "## exemple de l'utilisation de preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = preprocess(\"Temp\\S6030S07.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ce646",
   "metadata": {},
   "source": [
    "## affichage de l'exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c704f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('image.png', roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f05a1b",
   "metadata": {},
   "source": [
    "### Fonction : savepreprocessed\n",
    "Enregistre une image prétraitée dans un répertoire spécifié, créant le chemin de dossier si nécessaire. Cette fonction est utile pour organiser et stocker des images traitées dans une structure de répertoire ordonnée, facilitant l'accès et la gestion des données d'image dans des projets plus vastes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepreprocessed(image, folder, image_name):\n",
    "    path_preprocessed = 'Backend/0_Data/Preprocessed_Data'\n",
    "    if not os.path.exists(os.path.join(path_preprocessed, folder)):\n",
    "        os.makedirs(os.path.join(path_preprocessed, folder))\n",
    "    cv2.imwrite(os.path.join(path_preprocessed, folder, image_name + '.jpg'), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d88f1",
   "metadata": {},
   "source": [
    "### Traitement en lot et sauvegarde des images prétraitées\n",
    "\n",
    "Ce bloc de code parcourt un répertoire contenant des images brutes, les traite une par une, puis sauvegarde les résultats dans un répertoire approprié. Chaque image est lue, traitée via la fonction `preprocess`, et ensuite sauvegardée avec son nom d'origine (sans l'extension) dans un sous-dossier spécifique qui correspond à son dossier d'origine.\n",
    "\n",
    "**Détails du processus:**\n",
    "1. **Parcours des dossiers:** Le code parcourt chaque dossier dans le répertoire spécifié 'Backend/0_Data/Raw_Data/'.\n",
    "2. **Traitement des images:** Chaque image dans ces dossiers est traitée pour normaliser et améliorer les régions de l'iris.\n",
    "3. **Sauvegarde des images traitées:** Les images traitées sont sauvegardées dans une structure de dossier qui reflète leur organisation d'origine, aidant à maintenir une bonne gestion des données pour des analyses ultérieures.\n",
    "\n",
    "Ce processus automatise la préparation des images pour des systèmes de reconnaissance d'iris, assurant que toutes les images sont formatées de manière uniforme et stockées de manière organisée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ddf81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = 'Backend/0_Data/Raw_Data/'\n",
    "\n",
    "for folder in os.listdir(row_data):\n",
    "    folder_path = os.path.join(row_data, folder)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        preprocessed_image = preprocess(image_path)\n",
    "        savepreprocessed(preprocessed_image, folder, os.path.splitext(image_name)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78d1f7",
   "metadata": {},
   "source": [
    "### Description des fonctions de traitement d'image pour l'extraction de caractéristiques\n",
    "\n",
    "Ce code implémente plusieurs fonctions pour le traitement d'image, la modulation, et l'extraction de caractéristiques basées sur des filtres spatiaux, notamment des filtres de Gabor.\n",
    "\n",
    "1. **Fonctions de modulation et de filtrage Gabor :**\n",
    "   - `m(x, y, f)`: Module une valeur basée sur la fréquence et la position, utilisée pour créer des filtres de Gabor.\n",
    "   - `gabor(x, y, dx, dy, f)`: Calcule un filtre de Gabor en utilisant la modulation précédemment définie, caractérisé par des paramètres de dispersion `dx` et `dy` et une fréquence `f`.\n",
    "\n",
    "2. **Fonction pour calculer les filtres spatiaux :**\n",
    "   - `spatial(f, dx, dy)`: Génère un filtre spatial de 4x4 en utilisant la fonction `gabor`, adapté pour un traitement par blocs sur des images.\n",
    "\n",
    "3. **Extraction de vecteur de caractéristiques :**\n",
    "   - `get_vec(convolvedtrain1, convolvedtrain2)`: Extrait un vecteur de caractéristiques de deux images filtrées, en calculant la moyenne et l'écart-type des valeurs absolues sur des blocs de 4x4 pixels.\n",
    "\n",
    "4. **Extraction de caractéristiques globale :**\n",
    "   - `FeatureExtraction(enhanced)`: Applique les filtres spatiaux sur une région définie de l'image améliorée, extrait les vecteurs de caractéristiques pour chaque image dans un ensemble, et retourne un ensemble de vecteurs pour analyse ou apprentissage ultérieur.\n",
    "\n",
    "Chaque image est d'abord traitée pour extraire une région d'intérêt, puis convoluée avec deux filtres de Gabor différents. Les résultats sont utilisés pour construire des vecteurs de caractéristiques qui sont ensuite agrégés pour former un ensemble de données pour l'entraînement et le test dans des le modèles de reconnaissance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5054d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def m(x ,y, f):\n",
    "    val = np.cos(2*np.pi*f*math.sqrt(x **2 + y**2))\n",
    "    return val\n",
    "#spatial filter as defined in paper\n",
    "def gabor(x, y, dx, dy, f):\n",
    "    gb = (1/(2*math.pi*dx*dy))*np.exp(-0.5*(x**2 / dx**2 + y**2 / dy**2)) * m(x, y, f)\n",
    "    return gb\n",
    "\n",
    "#function to calculate spatial filter over 4x4 blocks\n",
    "def spatial(f,dx,dy):\n",
    "    sfilter=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            sfilter[i,j]=gabor((-2+j),(-2+i),dx,dy,f)\n",
    "    return sfilter\n",
    "\n",
    "def get_vec(convolvedtrain1,convolvedtrain2):\n",
    "    feature_vec=[]\n",
    "    for i in range(12):\n",
    "            for j in range(128):\n",
    "                #Run 4 by 4 filtered block iteratively over the entire image\n",
    "                start_height = i*4\n",
    "                end_height = start_height+4\n",
    "                start_wid = j*4\n",
    "                end_wid = start_wid+4\n",
    "                grid1 = convolvedtrain1[start_height:end_height, start_wid:end_wid]\n",
    "                grid2 = convolvedtrain2[start_height:end_height, start_wid:end_wid]\n",
    "\n",
    "                # Channel 1\n",
    "                absolute = np.absolute(grid1)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "                # Channel 2\n",
    "                absolute = np.absolute(grid2)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def FeatureExtraction(enhanced):\n",
    "    con1=[]\n",
    "    con2=[]\n",
    "    #get spatial filters\n",
    "    filter1=spatial(0.67,3,1.5)\n",
    "    filter2=spatial(0.67,4,1.5) \n",
    "    \n",
    "    feature_vector=[] #\n",
    "    \n",
    "    for i in range(len(enhanced)):\n",
    "        img=enhanced[i]\n",
    "        #define a 48x512 region over which the filters are applied\n",
    "        img_roi=img[0:48,:]\n",
    "        \n",
    "        filtered1=scipy.signal.convolve2d(img_roi,filter1,mode='same')\n",
    "        filtered2=scipy.signal.convolve2d(img_roi,filter2,mode='same')\n",
    "        \n",
    "        con1.append(filtered1)\n",
    "        con2.append(filtered2)\n",
    "        fv=get_vec(filtered1,filtered2)\n",
    "        feature_vector.append(fv)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37629f0",
   "metadata": {},
   "source": [
    "### Description du processus de chargement des données prétraitées\n",
    "\n",
    "Ce script parcourt un répertoire contenant des images prétraitées, les charge et les convertit en niveaux de gris pour préparer des données d'entraînement et de test pour le réseau de neurones . Il stocke également les étiquettes associées à chaque image, basées sur le nom du dossier, ce qui est utile pour des tâches de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb722f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = 'Backend/A_Data/Preprocessed_Data'\n",
    "label = []\n",
    "data = []\n",
    "for folder in os.listdir(preprocessed_data):  \n",
    "      folder_path = os.path.join(preprocessed_data, folder)\n",
    "      for image_preprocessed in os.listdir(folder_path):\n",
    "        input_preprocessedimg = cv2.imread(os.path.join(folder_path,image_preprocessed))\n",
    "        img= cv2.cvtColor(input_preprocessedimg, cv2.COLOR_BGR2GRAY)\n",
    "        label.append(folder)\n",
    "        data.append(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58feb423",
   "metadata": {},
   "source": [
    "### Description de l'application de l'extraction de caractéristiques\n",
    "\n",
    "Ce fragment de code utilise la fonction `FeatureExtraction` pour traiter une liste d'images et en extraire des caractéristiques. Cette étape est cruciale pour transformer les données visuelles brutes en un format plus adapté à l'apprentissage automatique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "new_data = FeatureExtraction(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895f16f",
   "metadata": {},
   "source": [
    "### Conversion des données et étiquettes en tableaux NumPy\n",
    "\n",
    "Ce fragment de code convertit les listes `label` et `new_data` en tableaux NumPy, facilitant ainsi leur manipulation et utilisation dans le réseau de neurones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = np.array(label)\n",
    "f2 = np.array(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f7de3",
   "metadata": {},
   "source": [
    "### Configuration d'un réseau de neurones pour la classification avec Keras\n",
    "\n",
    "Ce script configure et compile un modèle de réseau de neurones profond pour classer des images basées sur leurs vecteurs de caractéristiques. Il utilise Keras, une bibliothèque de deep learning populaire, pour construire et entraîner le modèle.\n",
    "\n",
    "**Processus de configuration :**\n",
    "1. **Préparation des données :**\n",
    "   - `x` et `y_` sont initialisés avec les tableaux `f2` et `f1` respectivement.\n",
    "   - Les étiquettes `y_` sont converties en format catégorique (`y`), utilisant `to_categorical` pour l'apprentissage supervisé.\n",
    "   - Les données sont divisées en ensembles d'entraînement et de test avec `train_test_split`, répartissant 20% des données pour le test.\n",
    "\n",
    "2. **Construction du modèle :**\n",
    "   - Le modèle utilise une architecture `Sequential` avec trois couches `Dense`. La première couche a 1024 unités, la seconde 2048, et la troisième (couche de sortie) 65 unités correspondant aux classes potentielles, toutes avec l'activation `relu` sauf la dernière qui utilise `softmax` pour la classification.\n",
    "   - Le modèle est compilé avec l'optimiseur `SGD` avec un momentum de 0.9, utilisant la `categorical_crossentropy` comme fonction de perte et mesurant `accuracy`.\n",
    "\n",
    "**Visualisation de la configuration du modèle :**\n",
    "- Un résumé du modèle est affiché pour vérifier sa structure et ses paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "x = f2\n",
    "y_ = f1\n",
    "y = to_categorical(y_)  \n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6144,), activation='relu', name='fc1'))\n",
    "model.add(Dense(2048, activation='relu', name='fc2'))\n",
    "model.add(Dense(65, activation='softmax', name='output'))\n",
    "\n",
    "\n",
    "optimizer = SGD(momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f608b",
   "metadata": {},
   "source": [
    "### Entraînement du modèle de réseau de neurones\n",
    "\n",
    "Ce script lance l'entraînement du modèle de réseau de neurones configuré précédemment. Il utilise les données divisées en ensembles d'entraînement et de test pour optimiser et évaluer le modèle au cours de plusieurs itérations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0762dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y,validation_data=(test_x,test_y), verbose=1, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81fef6",
   "metadata": {},
   "source": [
    "### Visualisation de la précision d'entraînement et de test\n",
    "\n",
    "Ce script génère un graphique pour visualiser la progression de la précision du modèle au cours de l'entraînement et de la validation. Ce graphique aide à identifier visuellement comment le modèle s'améliore avec chaque époque et à détecter des signes de sur-entraînement ou de sous-entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "train_acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "xc = range(100)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(xc,train_acc,label = 'Train accuracy')\n",
    "plt.plot(xc,val_acc,label='Test accuracy')\n",
    "plt.legend(loc='upper left',prop={'size':20})\n",
    "plt.title('Train and Test Accuracy plot',size=20)\n",
    "plt.xlabel('Epochs',size=20)\n",
    "plt.ylabel('Accuracy',size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256a226",
   "metadata": {},
   "source": [
    "## enregistrer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6cd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "model.save('Gabor+NN.h5')\n",
    "\n",
    "print(\"Le modèle a été sauvegardé avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122fe424",
   "metadata": {},
   "source": [
    "### Utilisation d'un modèle entraîné pour prédire la classe d'une image\n",
    "\n",
    "Ce script illustre comment charger et utiliser un modèle de réseau de neurones convolutif préalablement entraîné pour classer une image spécifique. Il démontre le processus complet de la charge du modèle, de la préparation de l'image, de l'extraction des caractéristiques, et de la prédiction de la classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Charger le modèle entraîné\n",
    "model = load_model('3_Model/Gabor_NN.h5')\n",
    "\n",
    "# Charger l'image à partir du dossier de normalisation\n",
    "image_path = 'Backend/0_Data\\Preprocessed_Data/009\\S6009S01.jpg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)\n",
    "# Extraire les caractéristiques de l'image\n",
    "features = FeatureExtraction([img])\n",
    "\n",
    "prediction = model.predict(np.array(features))\n",
    "\n",
    "# Trouver l'index de la classe avec la probabilité maximale\n",
    "predicted_class_index = np.argmax(prediction)\n",
    "\n",
    "# Afficher la classe prédite\n",
    "print(\"Classe prédite :\", predicted_class_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
